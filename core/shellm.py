import logging
import os
from datetime import datetime

from colorama import Fore, Style

from models.groq_model import GroqModel
from models.openai_model import OpenAIModel
from utils.schemas import Context
from .commands import change_directory, run_command_with_pty
from .ssh import run_interactive_ssh


logger = logging.getLogger(__name__)

class SheLLM:
    def __init__(self, llm_api):
        self.context: Context = Context()
        self.history = []
        self.current_process_pid = None
        if llm_api == 'groq':
            self.model = GroqModel()
        else:
            self.model = OpenAIModel()
        self.ssh_session = None
        logger.info(f"SheLLM initialized with {llm_api} model.")

    def update_context(self, output) -> None:
        """Updates the context object with new terminclass SheLLM."""
        self.update_command_history(output)
        self.capture_prior_command(output)
        logger.info(f"Updated the context after new output: {output}")

    def update_command_history(self, output) -> None:
        """Updates the entire context with new terminal output."""
        self.context.command_history += output + "\n"
        logger.debug(f"Updated history of all priorly entered commands: {self.context.command_history}")

    def capture_prior_command(self, output) -> None:
        """Updates the last command with new terminal output."""
        self.context.prior_command = output
        logger.debug(f"Updated prior command: {self.context.prior_command}")

    def execute_system_command(self, command):
        """Executes system commands and captures output."""
        if not command.strip():
            logger.info("No command entered. Please enter a valid command.")
            return

        tokens = command.split()
        if tokens[0] == 'cd':
            change_directory(tokens)
        elif tokens[0] == 'history':
            self.show_history()
        elif tokens[0] == 'ssh':
            run_interactive_ssh(tokens, self)
        else:
            output = run_command_with_pty(command)
            self.update_context(output)

    def handle_lm_command(self, command, remote=False):
        """Handles commands generated by the language model."""
        while True:
            suggestion = self.model.get_command_suggestion(self.context, command)
            if suggestion:
                logger.info(f"Execute command: {Fore.RED}{suggestion}{Style.RESET_ALL}")
                response = input(f"{Fore.RED}[SheLLM]{Style.RESET_ALL} Confirm execution (Y/n/r)").lower()
                if response == 'y':
                    if remote and self.ssh_session:
                        os.write(self.ssh_session, (suggestion + '\n').encode())
                    else:
                        self.execute_system_command(suggestion)
                    break
                elif response == 'n':
                    break
                elif response == 'r':
                    continue

    def answer_question(self, question):
        """Answers a question using the language model."""
        answer = self.model.answer_question(self.context, question)
        current_time = datetime.now().strftime('%H:%M:%S')
        logger.info(f"{Fore.RED}[SheLLM]{Style.RESET_ALL} {Fore.BLUE}[{current_time}]{Style.RESET_ALL} Answer: {Fore.GREEN}{answer}{Style.RESET_ALL}")
        return answer

    def show_history(self):
        """Shows corethe command history."""
        current_time = datetime.now().strftime('%H:%M:%S')
        if not self.history:
            logger.info(f"{Fore.RED}[SheLLM]{Style.RESET_ALL} {Fore.BLUE}[{current_time}]{Style.RESET_ALL} No command history.")
        else:
            logger.info(f"{Fore.RED}[SheLLM]{Style.RESET_ALL} {Fore.BLUE}[{current_time}]{Style.RESET_ALL} Command History:")
            for i, cmd in enumerate(self.history, 1):
                logger.info(f"{i}: {cmd}")
